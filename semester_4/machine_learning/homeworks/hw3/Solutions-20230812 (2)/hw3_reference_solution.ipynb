{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "NAMES_FILE = \"spambase.names\"\n",
    "CHARS_FOR_REGEX = [';', '\\(', '\\[', '!', '\\$', '#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts feature names from the 'names' file. takes address, returns list \n",
    "def feature_name_extractor(file):\n",
    "    names = []\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        names.extend(re.findall('word_freq_([a-z0-9]+):', line))\n",
    "    return names\n",
    "    \n",
    "feature_names = feature_name_extractor(NAMES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features anc characters from the file. takes in a file address, list of feature names and list of chars. returns dict\n",
    "def extract_fature(file, f_names, chars):\n",
    "    words = []\n",
    "    feature_freq = {i:0 for i in f_names}\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        whole_txt = f.read()\n",
    "        words.extend(re.findall('\\w+', whole_txt.lower()))\n",
    "    n_words = len(words)                            # number of all words\n",
    "    n_chars = len(re.findall('[^ ]', whole_txt))    # number of all characters except for whitespace\n",
    "    print(f\"Total number of: words={n_words}    characters={n_chars}\")\n",
    "\n",
    "    for item in feature_freq.keys():\n",
    "        count = words.count(item)\n",
    "        feature_freq[item] = (count / n_words) * 100\n",
    "\n",
    "    for char in chars:\n",
    "        count = len(re.findall(char, whole_txt))\n",
    "        feature_freq['char_freq_' + char[-1]] = (count / n_chars) * 100   # -1 is to remove the \\ that is needed for regex. selects only last character\n",
    "\n",
    "    capitals = re.findall('[A-Z]+', whole_txt)\n",
    "    feature_freq['capital_run_length_average'] = sum([len(c) for c in capitals]) / len(capitals)\n",
    "    feature_freq['capital_run_length_longest'] = max([len(c) for c in capitals])\n",
    "    feature_freq['capital_run_length_total'] = sum([len(c) for c in capitals])\n",
    "\n",
    "    return feature_freq\n",
    "\n",
    "# prints dictionary with costum number of keys in one row with tab and float rounding\n",
    "def print_n_by_n(my_dict, n):\n",
    "    for i, key in enumerate(my_dict.keys()):\n",
    "        print(f'{key}={my_dict[key]:.3f}', end='\\t')\n",
    "        if i % n == n-1:\n",
    "            print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of: words=223    characters=1362\n",
      "make=0.000\taddress=0.000\tall=0.000\t3d=0.000\tour=0.000\tover=0.000\t\n",
      "remove=0.000\tinternet=0.000\torder=0.000\tmail=0.000\treceive=0.000\twill=0.897\t\n",
      "people=0.000\treport=0.000\taddresses=0.000\tfree=0.000\tbusiness=0.000\temail=0.000\t\n",
      "you=0.448\tcredit=0.000\tyour=0.448\tfont=0.000\t000=0.000\tmoney=0.000\t\n",
      "hp=0.000\thpl=0.000\tgeorge=0.000\t650=0.000\tlab=0.000\tlabs=0.000\t\n",
      "telnet=0.000\t857=0.000\tdata=0.000\t415=0.000\t85=0.000\ttechnology=0.000\t\n",
      "1999=0.000\tparts=0.000\tpm=0.000\tdirect=0.000\tcs=0.000\tmeeting=0.000\t\n",
      "original=0.000\tproject=0.000\tre=0.000\tedu=0.000\ttable=0.000\tconference=0.000\t\n",
      "char_freq_;=0.000\tchar_freq_(=0.220\tchar_freq_[=0.220\tchar_freq_!=0.073\tchar_freq_$=0.000\tchar_freq_#=0.073\t\n",
      "capital_run_length_average=1.167\tcapital_run_length_longest=2.000\tcapital_run_length_total=56.000\t"
     ]
    }
   ],
   "source": [
    "# First mail\n",
    "first_mail = extract_fature('spam_or_no_spam.txt', feature_names, CHARS_FOR_REGEX)\n",
    "print_n_by_n(first_mail, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of: words=71    characters=369\n",
      "make=0.000\taddress=0.000\tall=0.000\t3d=0.000\tour=0.000\tover=0.000\t\n",
      "remove=0.000\tinternet=0.000\torder=0.000\tmail=1.408\treceive=0.000\twill=0.000\t\n",
      "people=0.000\treport=0.000\taddresses=0.000\tfree=0.000\tbusiness=0.000\temail=4.225\t\n",
      "you=1.408\tcredit=0.000\tyour=1.408\tfont=0.000\t000=0.000\tmoney=0.000\t\n",
      "hp=0.000\thpl=0.000\tgeorge=0.000\t650=0.000\tlab=0.000\tlabs=0.000\t\n",
      "telnet=0.000\t857=0.000\tdata=0.000\t415=0.000\t85=0.000\ttechnology=0.000\t\n",
      "1999=0.000\tparts=0.000\tpm=0.000\tdirect=0.000\tcs=0.000\tmeeting=0.000\t\n",
      "original=0.000\tproject=0.000\tre=1.408\tedu=0.000\ttable=0.000\tconference=0.000\t\n",
      "char_freq_;=0.000\tchar_freq_(=0.000\tchar_freq_[=0.000\tchar_freq_!=0.000\tchar_freq_$=0.000\tchar_freq_#=0.000\t\n",
      "capital_run_length_average=1.364\tcapital_run_length_longest=5.000\tcapital_run_length_total=45.000\t"
     ]
    }
   ],
   "source": [
    "# Second mail\n",
    "second_mail = extract_fature('spam_or_no_spam_2.txt', feature_names, CHARS_FOR_REGEX)\n",
    "print_n_by_n(second_mail, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of: words=131    characters=711\n",
      "make=0.000\taddress=0.000\tall=0.000\t3d=0.000\tour=0.763\tover=0.000\t\n",
      "remove=0.000\tinternet=0.000\torder=0.000\tmail=0.000\treceive=0.000\twill=0.000\t\n",
      "people=0.000\treport=0.000\taddresses=0.000\tfree=0.000\tbusiness=3.053\temail=0.000\t\n",
      "you=1.527\tcredit=0.000\tyour=1.527\tfont=0.000\t000=0.000\tmoney=0.000\t\n",
      "hp=0.000\thpl=0.000\tgeorge=0.000\t650=0.000\tlab=0.000\tlabs=0.000\t\n",
      "telnet=0.000\t857=0.000\tdata=0.000\t415=0.000\t85=0.000\ttechnology=0.000\t\n",
      "1999=0.000\tparts=0.000\tpm=0.000\tdirect=0.000\tcs=0.000\tmeeting=0.000\t\n",
      "original=0.000\tproject=1.527\tre=0.000\tedu=0.000\ttable=0.000\tconference=0.000\t\n",
      "char_freq_;=0.141\tchar_freq_(=0.141\tchar_freq_[=0.000\tchar_freq_!=0.000\tchar_freq_$=0.000\tchar_freq_#=0.000\t\n",
      "capital_run_length_average=1.657\tcapital_run_length_longest=10.000\tcapital_run_length_total=58.000\t"
     ]
    }
   ],
   "source": [
    "# Third mail\n",
    "third_mail = extract_fature('spam_or_no_spam_3.txt', feature_names, CHARS_FOR_REGEX)\n",
    "print_n_by_n(third_mail, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
